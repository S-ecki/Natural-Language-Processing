{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Exercise Sheet 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for all exercises\n",
    "import nltk\n",
    "from nltk.classify import apply_features, accuracy\n",
    "from nltk.corpus import names, ppattach, senseval, movie_reviews\n",
    "import random\n",
    "from statistics import mean\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a name gender classifier using the Names Corpus, the `apply_features` function, shuffling, and a test set of 500 instances. Use the following features:\n",
    "\n",
    "a) first letter;  \n",
    "b) last letter;  \n",
    "c) last two letters;  \n",
    "d) length;  \n",
    "e) for each letter one feature, which is true if the name contains the letter.\n",
    "\n",
    "Use the `NaiveBayesClassifier`, calculate the accuracy, and display the 10 most informative features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    features = {}\n",
    "  \n",
    "    features['first_letter'] = word[0].lower()\n",
    "    features['last_letter'] = word[-1].lower()\n",
    "    features['last_two_lettes'] = word[-2:].lower()\n",
    "    features['length'] = len(word)\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"has({})\".format(letter)] = (letter in word.lower())\n",
    "    \n",
    "    return features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "random.shuffle(labeled_names)\n",
    "train_set = apply_features(gender_features, labeled_names[500:])\n",
    "test_set = apply_features(gender_features, labeled_names[:500])\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The Senseval 2 Corpus contains data intended to train word-sense disambiguation classifiers. Using this dataset, build a `NaiveBayesClassifier` that predicts the correct sense tag for a given instance for the word \"hard\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the preceding and following word as features. They can be calculated by retrieving the position of the word \"hard\" as `p=inst.position` and then accessing `inst.context[p-1]` and `inst.context[p+1]`.\n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the individual accuracies. Finally, print the average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(inst):\n",
    "    pos = inst.position\n",
    "    prev = inst.context[pos-1][0]\n",
    "    next = inst.context[pos+1][0]\n",
    "\n",
    "    return {\n",
    "        'prev_word': prev,\n",
    "        'next_word': next\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = senseval.instances('hard.pos')\n",
    "labeled_instances = [(inst, inst.senses) for inst in instances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(labeled_instances) * 0.1)\n",
    "accuracy_memory = []\n",
    "\n",
    "for i in range(10):\n",
    "    random.shuffle(labeled_instances)\n",
    "    train_set = apply_features(features, labeled_instances[size:])\n",
    "    test_set = apply_features(features, labeled_instances[:size])\n",
    "\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    \n",
    "    acc = accuracy(classifier, test_set)\n",
    "    accuracy_memory.append(acc)\n",
    "    print( 'Accuracy of run {}: {}'.format(i+1, acc) )\n",
    "\n",
    "\n",
    "avg = mean(accuracy_memory)\n",
    "print( 'Overall Accuracy of 10 runs: {}'.format(avg) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "The synonyms \"strong\" and \"powerful\" pattern differently. Use the tagged Brown corpus with the universal tagset to first list the nouns which follow \"strong\" vs. \"powerful\". Write for this a function `next_noun(word, tagged_text)` which returns the list of nouns that follow `word` in the `tagged_text`. Build then a `NaiveBayesClassifier` that predicts when each word should be used by using the function `apply_features` and the following noun as single feature.\n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the individual accuracies. Finally, print the average accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_noun(word, tagged_text):\n",
    "  return [ b[0] for (a, b) in nltk.bigrams(tagged_text) if a[0] == word and b[1] == 'NOUN' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_nouns = next_noun('strong', nltk.corpus.brown.tagged_words(tagset='universal'))\n",
    "powerful_nouns = next_noun('powerful', nltk.corpus.brown.tagged_words(tagset='universal'))\n",
    "\n",
    "strong_nouns_tagged = [ (n, 'strong') for n in strong_nouns ]\n",
    "powerful_nouns_tagged = [ (n, 'powerful') for n in powerful_nouns ]\n",
    "\n",
    "combined_nouns_tagged = strong_nouns_tagged + powerful_nouns_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_feature(word):\n",
    "    return {'word': word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(combined_nouns_tagged) * 0.1)\n",
    "accuracy_cache = []\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    random.shuffle(combined_nouns_tagged)\n",
    "    train_set = apply_features(word_feature, combined_nouns_tagged[size:])\n",
    "    test_set = apply_features(word_feature, combined_nouns_tagged[:size])\n",
    "\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    \n",
    "    acc = accuracy(classifier, test_set)\n",
    "    accuracy_cache.append(acc)\n",
    "    print('Accuracy in round {}: {}'.format(i+1, acc))\n",
    "\n",
    "mean_acc = mean(accuracy_cache)\n",
    "print('Mean Accuracy of 10 tries: {}'.format(mean_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Based on the Movie Reviews document classifier discussed in this chapter, build a new `NaiveBayesClassifier`. Tag first the Movie Reviews Corpus using the combined tagger from the previous chapter stored in `t2.pkl`. Filter the tagged words to contain only words for the tags `['JJ', 'JJR', 'JJS', 'RB', 'NN', 'NNS', 'VB', 'VBN', 'VBG', 'VBZ', 'VBD', 'QL']` as well as only alphabetic tokens with at least three characters. Convert the words to lowercase. Use the most common 5000 words as `word_features` in the function `document_features`. \n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the accuracy and 5 most informative features for each iteration. Finally, print the average accuracy.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports tagger for tokenized text from chapter 5\n",
    "input = open('t2.pkl', 'rb')\n",
    "tagger = load(input)\n",
    "input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates documents with list of tagged words and movie review\n",
    "documents_tagged = [(tagger.tag(movie_reviews.words(fileid)), category)\n",
    "                    for category in movie_reviews.categories()\n",
    "                    for fileid in movie_reviews.fileids(category)\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tags = ['JJ', 'JJR', 'JJS', 'RB', 'NN', 'NNS', 'VB', 'VBN', 'VBG', 'VBZ', 'VBD', 'QL']\n",
    "\n",
    "# filter out words without tags from target_tags, words that are not alphabetic and shorter than 3 chars\n",
    "# also converts words to lowercase and discards tags, as they are not needed anymore\n",
    "documents_filtered = []\n",
    "for (tag_words, cat) in documents_tagged:\n",
    "    words_temp = []\n",
    "    for(w, tag) in tag_words:\n",
    "        if w.isalpha() and len(w) > 2 and tag in target_tags:\n",
    "            words_temp.append(w.lower())\n",
    "    documents_filtered.append((words_temp, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 5000 most common words to use as features\n",
    "fdist = nltk.FreqDist( w for (words, cat) in documents_filtered for w in words )\n",
    "word_features = list(fdist)[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of run 1: 0.8\n",
      "Most Informative Features\n",
      "     contains(insulting) = True              neg : pos    =     16.3 : 1.0\n",
      "     contains(ludicrous) = True              neg : pos    =     14.6 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =     13.7 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     10.5 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     10.2 : 1.0\n",
      "Accuracy of run 2: 0.82\n",
      "Most Informative Features\n",
      "   contains(magnificent) = True              pos : neg    =     20.4 : 1.0\n",
      "         contains(sucks) = True              neg : pos    =     16.3 : 1.0\n",
      "     contains(maintains) = True              pos : neg    =     13.0 : 1.0\n",
      "   contains(outstanding) = True              pos : neg    =     12.6 : 1.0\n",
      "       contains(tribute) = True              pos : neg    =     11.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "size = int(len(documents_filtered) * 0.1)\n",
    "accuracy_memory = []\n",
    "\n",
    "for i in range(10):\n",
    "    random.shuffle(documents_filtered)\n",
    "    train_set = apply_features(document_features, documents_filtered[size:])\n",
    "    test_set = apply_features(document_features, documents_filtered[:size])\n",
    "\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    acc = accuracy(classifier, test_set)\n",
    "    accuracy_memory.append(acc)\n",
    "    print( '\\nAccuracy of run {}: {}'.format(i+1, acc) )\n",
    "    # print( '5 Most informative features: {}\\n'.format(classifier.show_most_informative_features(5)) )\n",
    "    classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of 10 runs: 0.8200000000000001\n"
     ]
    }
   ],
   "source": [
    "avg = mean(accuracy_memory)\n",
    "print( 'Overall Accuracy of 10 runs: {}'.format(avg) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "The PP Attachment Corpus is a corpus describing prepositional phrase attachment decisions. Each instance in the training corpus is encoded as a `PPAttachment` object:\n",
    "\n",
    "    from nltk.corpus import ppattach\n",
    "    ppattach.attachments('training')\n",
    "    \n",
    "        [PPAttachment(sent='0', verb='join', noun1='board',\n",
    "            prep='as', noun2='director', attachment='V'),\n",
    "        PPAttachment(sent='1', verb='is', noun1='chairman',\n",
    "            prep='of', noun2='N.V.', attachment='N'),\n",
    "        ...]\n",
    "\n",
    "    inst = ppattach.attachments('training')[1]\n",
    "    (inst.noun1, inst.prep, inst.noun2)\n",
    "    \n",
    "        ('chairman', 'of', 'N.V.')\n",
    "\n",
    "In the same way, `ppattach.attachments('test')` accesses the test instances. Select only the instances where `inst.attachment` is `'N'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nattach = [inst for inst in ppattach.attachments('training')\n",
    "               if inst.attachment == 'N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this sub-corpus, build a `NaiveBayesClassifier` that attempts to predict which preposition is used to connect a given pair of nouns. For example, given the pair of nouns \"team\" and \"researchers\", the classifier should predict the preposition \"of\". \n",
    "\n",
    "Write for this purpose a function `prepare_featuresets(subcorpus)`, where `subcorpus` is either the string \"training\" or \"test\" to return the training set or the test set. \n",
    "\n",
    "Print the achieved accuracy as well as the result of `classifier.classify({ 'noun1': 'team', 'noun2': 'researchers' })`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preposition_features(att):\n",
    "    return ({'noun1': att.noun1, 'noun2': att.noun2}, att.prep)\n",
    "    \n",
    "def prepare_featuresets(subcorpus):\n",
    "    nattach = [inst for inst in ppattach.attachments(subcorpus)\n",
    "               if inst.attachment == 'N']\n",
    "    \n",
    "    return apply_features(preposition_features, nattach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = prepare_featuresets('training')\n",
    "test_set = prepare_featuresets('test')\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Accuracy: {}'.format( accuracy(classifier, test_set) ) )\n",
    "print( classifier.classify({'noun1': 'team', 'noun2': 'researchers'}) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
