{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Exercise Sheet 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for all exercises\n",
    "import pprint\n",
    "from nltk import corpus, FreqDist, memoize\n",
    "from nltk.corpus import wordnet as wn\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a program to initialize a two-dimensional array of sets called `word_vowels` and process a list of words, adding each word to `word_vowels[l][v]` where $l$ is the length of the word and $v$ is the number of vowels it contains. Test your program with a 10x10-array and the list `['Alice', 'hat', 'heute', 'ihren', 'freien', 'Tag']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[set(), set(), set(), set(), set(), set(), set(), set(), set(), set()],\n",
       " [set(), set(), set(), set(), set(), set(), set(), set(), set(), set()],\n",
       " [set(), set(), set(), set(), set(), set(), set(), set(), set(), set()],\n",
       " [set(),\n",
       "  {'Tag', 'hat'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set()],\n",
       " [set(), set(), set(), set(), set(), set(), set(), set(), set(), set()],\n",
       " [set(),\n",
       "  set(),\n",
       "  {'Alice', 'ihren'},\n",
       "  {'heute'},\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set(),\n",
       "  set()],\n",
       " [set(), set(), set(), {'freien'}, set(), set(), set(), set(), set(), set()],\n",
       " [set(), set(), set(), set(), set(), set(), set(), set(), set(), set()],\n",
       " [set(), set(), set(), set(), set(), set(), set(), set(), set(), set()],\n",
       " [set(), set(), set(), set(), set(), set(), set(), set(), set(), set()]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_vowels(words, dim):\n",
    "    # creates array with dim x dim sets\n",
    "    word_vowels =  [ [ set() for _ in range(dim) ] for _ in range(dim) ]\n",
    "    for word in words:\n",
    "        l = len(word)\n",
    "        # number of vowels in word\n",
    "        v = sum( 1 for c in word if c in 'aeiou' )\n",
    "        word_vowels[l][v].add(word)\n",
    "    return word_vowels\n",
    "\n",
    "word_vowels(['Alice', 'hat', 'heute', 'ihren', 'freien', 'Tag'], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Write a program that prints all words that only appear in the last 10\\% of a text. Test your code with the file `'shakespeare-macbeth.txt'` from the Gutenberg Corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abhorred',\n",
       " 'absent',\n",
       " 'aduance',\n",
       " 'aduantage',\n",
       " 'ague',\n",
       " 'alarums',\n",
       " 'alowd',\n",
       " 'appeare',\n",
       " 'approaches',\n",
       " 'arbitrate',\n",
       " 'army',\n",
       " 'arriu',\n",
       " 'auouches',\n",
       " 'auoyded',\n",
       " 'backward',\n",
       " 'baited',\n",
       " 'bane',\n",
       " 'battell',\n",
       " 'bear',\n",
       " 'beard',\n",
       " 'beaten',\n",
       " 'beest',\n",
       " 'befor',\n",
       " 'beleeu',\n",
       " 'birnane',\n",
       " 'bloodier',\n",
       " 'bough',\n",
       " 'boughes',\n",
       " 'brandish',\n",
       " 'brauely',\n",
       " 'breefe',\n",
       " 'bruited',\n",
       " 'butcher',\n",
       " 'calling',\n",
       " 'candle',\n",
       " 'censures',\n",
       " 'chambers',\n",
       " 'cheapely',\n",
       " 'childrens',\n",
       " 'clamorous',\n",
       " 'clatter',\n",
       " 'com',\n",
       " 'compast',\n",
       " 'confident',\n",
       " 'constrained',\n",
       " 'continued',\n",
       " 'cool',\n",
       " 'cosins',\n",
       " 'cow',\n",
       " 'creepes',\n",
       " 'crests',\n",
       " 'cyme',\n",
       " 'darefull',\n",
       " 'debt',\n",
       " 'decision',\n",
       " 'direnesse',\n",
       " 'discouery',\n",
       " 'drugge',\n",
       " 'dusty',\n",
       " 'earles',\n",
       " 'either',\n",
       " 'endure',\n",
       " 'equiuocation',\n",
       " 'erre',\n",
       " 'euent',\n",
       " 'exil',\n",
       " 'expence',\n",
       " 'fairer',\n",
       " 'familiar',\n",
       " 'famine',\n",
       " 'fearefull',\n",
       " 'fiends',\n",
       " 'fighting',\n",
       " 'finis',\n",
       " 'flying',\n",
       " 'forc',\n",
       " 'forgot',\n",
       " 'gaze',\n",
       " 'gently',\n",
       " 'ghosts',\n",
       " 'ginne',\n",
       " 'groue',\n",
       " 'haires',\n",
       " 'harbingers',\n",
       " 'hardly',\n",
       " 'harnesse',\n",
       " 'hatefull',\n",
       " 'hear',\n",
       " 'heereafter',\n",
       " 'henceforth',\n",
       " 'hew',\n",
       " 'hoast',\n",
       " 'horrors',\n",
       " 'hoter',\n",
       " 'hound',\n",
       " 'hurts',\n",
       " 'hyr',\n",
       " 'ideot',\n",
       " 'indure',\n",
       " 'industrious',\n",
       " 'intrenchant',\n",
       " 'iugling',\n",
       " 'knoll',\n",
       " 'leade',\n",
       " 'learne',\n",
       " 'leauy',\n",
       " 'loosest',\n",
       " 'lt',\n",
       " 'lyar',\n",
       " 'lyest',\n",
       " 'malcolmes',\n",
       " 'measur',\n",
       " 'minds',\n",
       " 'missing',\n",
       " 'monsters',\n",
       " 'mothers',\n",
       " 'mouing',\n",
       " 'newer',\n",
       " 'newly',\n",
       " 'next',\n",
       " 'oppos',\n",
       " 'outward',\n",
       " 'paid',\n",
       " 'palter',\n",
       " 'parted',\n",
       " 'pearle',\n",
       " 'petty',\n",
       " 'planted',\n",
       " 'player',\n",
       " 'pole',\n",
       " 'producing',\n",
       " 'professes',\n",
       " 'profit',\n",
       " 'proue',\n",
       " 'prowesse',\n",
       " 'purgatiue',\n",
       " 'rabbles',\n",
       " 'rarer',\n",
       " 'reckon',\n",
       " 'recorded',\n",
       " 'rendred',\n",
       " 'resolution',\n",
       " 'retreat',\n",
       " 'ript',\n",
       " 'roman',\n",
       " 'rowze',\n",
       " 'rubarb',\n",
       " 'salutation',\n",
       " 'score',\n",
       " 'scowre',\n",
       " 'sence',\n",
       " 'seru',\n",
       " 'seyw',\n",
       " 'sheath',\n",
       " 'shield',\n",
       " 'shrieke',\n",
       " 'siedge',\n",
       " 'signifying',\n",
       " 'skreenes',\n",
       " 'slaughterous',\n",
       " 'snares',\n",
       " 'soldier',\n",
       " 'souldiership',\n",
       " 'speculatiue',\n",
       " 'stake',\n",
       " 'staues',\n",
       " 'stroake',\n",
       " 'struts',\n",
       " 'sun',\n",
       " 'syw',\n",
       " 'tarrying',\n",
       " 'taste',\n",
       " 'tearmes',\n",
       " 'tels',\n",
       " 'thereby',\n",
       " 'tied',\n",
       " 'treatise',\n",
       " 'trumpets',\n",
       " 'try',\n",
       " 'vnbattered',\n",
       " 'vndeeded',\n",
       " 'vndon',\n",
       " 'vnshrinking',\n",
       " 'vnsure',\n",
       " 'voice',\n",
       " 'voyces',\n",
       " 'vsurpers',\n",
       " 'vulnerable',\n",
       " 'walls',\n",
       " 'watchfull',\n",
       " 'weapons',\n",
       " 'weary',\n",
       " 'womb',\n",
       " 'wrath',\n",
       " 'writ',\n",
       " 'yesterdayes']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def last_ten_percent_words(text):\n",
    "    cutoff = int(len(text) * 0.9)\n",
    "    # set of words used in first 90% of text -> case insensitive and only alphabetical\n",
    "    first_part = set( w.lower() for w in text[: cutoff] if w.isalpha() )\n",
    "    # set of words used in last 10% of text\n",
    "    last_part = set( w.lower() for w in text[cutoff :] if w.isalpha() )\n",
    "    # set of words ONLY used in last part (not present in first)\n",
    "    only_last_part = set( w for w in last_part if not w in first_part )\n",
    "    return sorted(only_last_part)\n",
    "\n",
    "shakespeare = corpus.gutenberg.words('shakespeare-macbeth.txt')\n",
    "last_ten_percent_words(shakespeare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Write a program that takes a sentence expressed as a single string, splits it and counts up the words. Get it to print out each word and the word's frequency, one per line, in alphabetical order. Test it with the sentence: `'das ist heute wieder einmal wirklich ein sehr schöner tag das kann ich dir wieder einmal sagen'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "das: 2\n",
      "dir: 1\n",
      "ein: 1\n",
      "einmal: 2\n",
      "heute: 1\n",
      "ich: 1\n",
      "ist: 1\n",
      "kann: 1\n",
      "sagen: 1\n",
      "schöner: 1\n",
      "sehr: 1\n",
      "tag: 1\n",
      "wieder: 2\n",
      "wirklich: 1\n"
     ]
    }
   ],
   "source": [
    "def print_word_freq(sentence):\n",
    "    words = sentence.split()\n",
    "    fdist = FreqDist(words)\n",
    "    # creates sorted set of tuples with (word, corresponding frequency)\n",
    "    word_and_freq = sorted(set( (word, fdist[word]) for word in words ))\n",
    "    for wf in word_and_freq:\n",
    "        print(f'{wf[0]}: {wf[1]}')\n",
    "\n",
    "sentence = 'das ist heute wieder einmal wirklich ein sehr schöner tag das kann ich dir wieder einmal sagen'\n",
    "\n",
    "print_word_freq(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Write a function `sort_dist(candidates, target)`. The `candidates` are a list of strings representing WordNet synset names, and `target` a synset name string. The function shall sort the `candidates` for proximity to the `target` synset using `shortest_path_distance()`. \n",
    "\n",
    "Test your function with `candidates=['minke_whale.n.01','orca.n.01','novel.n.01', 'tortoise.n.01']` and `target='right_whale.n.01'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 'minke_whale.n.01'),\n",
       " (5, 'orca.n.01'),\n",
       " (12, 'tortoise.n.01'),\n",
       " (22, 'novel.n.01')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sort_dist(candidates, target):\n",
    "    cand_and_syn = [ (c, wn.synset(c)) for c in candidates ]\n",
    "    targ_syn = wn.synset(target)\n",
    "    shortest_paths = [ (targ_syn.shortest_path_distance(cs), c) for c, cs in cand_and_syn ]\n",
    "    return sorted(shortest_paths)\n",
    "\n",
    "\n",
    "sort_dist(['minke_whale.n.01', 'orca.n.01', 'novel.n.01', 'tortoise.n.01'], 'right_whale.n.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Write a recursive function `lookup(trie, key)` that looks up a `key` in a `trie`, and returns the value it finds. The function should cover the following cases:\n",
    "\n",
    "a) it should return a corresponding message if the key is not included in the trie;  \n",
    "b) it should return a message if the key is not unique, i.e. if there are several words for this prefix;  \n",
    "c) if a word is uniquely determined by the key prefix it should be returned as result. \n",
    "\n",
    "Try your function for the following trie and test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': {'h': {'a': {'i': {'r': {'value': 'flesh'}},\n",
      "                   't': {'value': 'cat'}},\n",
      "             'e': {'v': {'a': {'l': {'value': 'horse'}}}},\n",
      "             'i': {'c': {'value': 'stylish'},\n",
      "                   'e': {'n': {'value': 'dog'}}}}}}\n"
     ]
    }
   ],
   "source": [
    "def insert(trie, key, value):\n",
    "    if key:\n",
    "        first, rest = key[0], key[1:]\n",
    "        if first not in trie:\n",
    "            trie[first] = {}\n",
    "        insert(trie[first], rest, value)\n",
    "    else:\n",
    "        trie['value'] = value\n",
    "\n",
    "trie = {}\n",
    "insert(trie, 'chat', 'cat')\n",
    "insert(trie, 'chien', 'dog')\n",
    "insert(trie, 'chair', 'flesh')\n",
    "insert(trie, 'chic', 'stylish')\n",
    "insert(trie, 'cheval','horse')\n",
    "trie = dict(trie)             \n",
    "pprint.pprint(trie, width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(trie, key):\n",
    "    # recursively call function for every char of key\n",
    "    # return if key is not in trie\n",
    "    if key:\n",
    "        try:\n",
    "            return lookup(trie[key[0]], key[1:])\n",
    "        except:\n",
    "            return 'Given Key was not found!'\n",
    "    else:\n",
    "        # return if exact key is in trie \n",
    "        try:\n",
    "            return trie['value']\n",
    "        except:\n",
    "            # skip mappings as long as they are unique\n",
    "            # word could still be uniquely(!) defined by key prefix\n",
    "            if len(trie) == 1:\n",
    "                k = list(trie.keys())[0]\n",
    "                return lookup(trie[k], '')\n",
    "            # return if mapping is not unique\n",
    "            else:\n",
    "                return 'Given Key was not unique!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "Given Key was not unique!\n",
      "Given Key was not found!\n",
      "horse\n",
      "horse\n",
      "horse\n"
     ]
    }
   ],
   "source": [
    "print(lookup(trie, 'chat'))\n",
    "print(lookup(trie, 'cha'))\n",
    "print(lookup(trie, 'souris'))\n",
    "print(lookup(trie, 'cheval'))\n",
    "print(lookup(trie, 'che'))\n",
    "print(lookup(trie, 'chev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Write a recursive function `pp_trie` that pretty prints a trie in alphabetically sorted order by replacing common prefixes with `'-'` characters.\n",
    "Test your implementation with the following example data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I did not finish this exercise**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "The *Catalan numbers* arise in many applications of combinatorial mathematics, including the counting of parse trees. The series can be defined as follows: $C_0 = 1$, and $C_{n+1} = \\sum_{i=0}^{n}C_iC_{n-i}$ for $n\\geq{0}$.\n",
    "\n",
    "Write:\n",
    "\n",
    "a) a recursive function `cn(n)` to compute the $n$th Catalan number $C_{n}$,  \n",
    "b) a corresponding function `cn2(n)` that uses dynamic programming by storing calculated solutions in a lookup table,  \n",
    "c) a function `cn3(n)`, which is identical to `cn(n)` but uses a `memoize` decorator.\n",
    "\n",
    "Test your functions first by calculating the Catalan numbers $C_0\\dots C_{16}$ and then by using the `timeit` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cn(n):\n",
    "    if n < 2:\n",
    "        return 1\n",
    "    else: \n",
    "        sum = 0\n",
    "        for i in range(n):\n",
    "            sum += cn(i) * cn(n-i-1)\n",
    "        return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "def cn2(n):\n",
    "    # init lookup with zeros\n",
    "    lookup = [0] * (n+1)\n",
    "\n",
    "    for i in range(n+1):\n",
    "        # known values: cn(0) = cn(1) = 1\n",
    "        if i < 2:\n",
    "            lookup[i] = 1\n",
    "            continue\n",
    "        # rest per definition\n",
    "        for j in range(i):\n",
    "            lookup[i] += lookup[j] * lookup[i - j - 1]\n",
    "\n",
    "    return lookup[n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n",
    "@memoize\n",
    "def cn3(n):\n",
    "    if n < 2:\n",
    "        return 1\n",
    "    else: \n",
    "        sum = 0\n",
    "        for i in range(n):\n",
    "            sum += cn(i) * cn(n-i-1)\n",
    "        return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.219280200000014\n",
      "0.00011419999998452113\n",
      "3.4431681000000367\n"
     ]
    }
   ],
   "source": [
    "print(timeit.timeit(\"cn(16)\", setup=\"from __main__ import cn\", number=5))\n",
    "print(timeit.timeit(\"cn2(16)\", setup=\"from __main__ import cn2\", number=5))\n",
    "print(timeit.timeit(\"cn3(16)\", setup=\"from __main__ import cn3\", number=5))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd07f1942820ca3e8ba041abc15020134a68dada3655f09eb421fdc1f23ae076"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
